---
id: "CVAM-11"
title: "Toward Scalable Video Narration: A Training-free Approach using Multimodal Large Language Models"
authors:
- Tz-Ying Wu
- Tahani Trigui
- Sharath Nittur Sridhar
- Anand Bodas
- Subarna Tripathi
type: "full"
session: "Whitepaper Presentations #2 - Oct 20 3:00 PM HST"
arxiv_link: https://arxiv.org/pdf/2507.17050?
abstract: "In this paper, we introduce VideoNarrator, a novel training-free pipeline designed to generate dense video captions that offer a structured snapshot of video content. These captions offer detailed narrations with precise timestamps, capturing the nuances present in each segment of the video. Despite advancements in multimodal large language models (MLLMs) for video comprehension, these models often struggle with temporally aligned narrations and tend to hallucinate, particularly in unfamiliar scenarios. VideoNarrator addresses these challenges by leveraging a flexible pipeline where off-the-shelf MLLMs and visual-language models (VLMs) can function as caption generators, context providers, or caption verifiers. Our experimental results demonstrate that the synergistic interaction of these components significantly enhances the quality and accuracy of video narrations, effectively reducing hallucinations and improving temporal alignment. This structured approach not only enhances video understanding but also facilitates downstream tasks such as video summarization and video question answering, and can be potentially extended for advertising and marketing applications."
---
